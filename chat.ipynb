{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrRf9x1wwLSV"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF requests faiss-cpu numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jkr7aj4qwvdP"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Step 1: Read PDF and Split into Pages\n",
        "def read_pdf(file_path):\n",
        "    \"\"\"\n",
        "    Read the PDF file and split it into individual pages.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(file_path)\n",
        "    pages = {}\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)\n",
        "        pages[page_num] = page.get_text()  # Extract text from page\n",
        "    return pages\n",
        "\n",
        "\n",
        "def generate_markdown_from_page(text, prompt, api_key):\n",
        "    \"\"\"\n",
        "    Generate markdown using Gemini API based on the extracted text from the page.\n",
        "    \"\"\"\n",
        "\n",
        "    api_url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    payload = {\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": prompt + \" \\n \" + text}]}]}\n",
        "    response = requests.post(f\"{api_url}?key={api_key}\", json=payload, headers=headers)\n",
        "    return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].strip()\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        try:\n",
        "            response_data = response.json()\n",
        "            print(response_data)  # Debug: Print the full response to understand its structure\n",
        "            return response_data.get('output', '')\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error decoding JSON response\")\n",
        "            return \"\"\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        print(response.text)  # Debug: Print the error message returned by the API\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "\n",
        "def process_pdf(pdf_path, gemini_api_key):\n",
        "    \"\"\"\n",
        "    Process the PDF by extracting text and generating markdown for each page.\n",
        "    \"\"\"\n",
        "    pages_dict = read_pdf(pdf_path)\n",
        "    markdowns = {}\n",
        "    for page_num, text in pages_dict.items():\n",
        "        prompt = \"\"\"\n",
        "\n",
        "**Prompt:**\n",
        "\n",
        "\"Analyze the provided  **textual information** and generate a structured markdown output that includes the following:\n",
        "\n",
        "1. **Headings and Text**: Extract all headings, subheadings, and body text. Format them as markdown headings (`##`, `###`, etc.) and bullet points or paragraphs where applicable. Include any annotations, references, or footnotes.\n",
        "\n",
        "2. **Tables**: Identify and extract all tables. Format them as markdown tables, ensuring that headers, rows, and columns are properly structured. Include any metadata or descriptions associated with the table.\n",
        "\n",
        "3. **Figures and Charts**: Extract descriptions of figures, charts, and graphs. Provide a detailed markdown description of the visual, including axes, data points, trends, and legends. If applicable, include the type of chart (e.g., bar chart, line graph, pie chart).\n",
        "\n",
        "4. **Page Metadata**: Extract page numbers, footers, and any other metadata. Format them as markdown text with appropriate labels (e.g., `### Page Number`, `### Page Footer`).\n",
        "\n",
        "5. **Grounding Information**: For each extracted element (text, table, figure, etc.), include grounding information such as the bounding box coordinates (`l`, `t`, `r`, `b`) and the page number where the element is located.\n",
        "\n",
        "6. **Chunking**: Organize the output into chunks, where each chunk represents a distinct element (e.g., a paragraph, table, figure). Assign a unique `chunk_id` to each chunk and specify its type (e.g., `text`, `table`, `figure`, `page_number`, `page_footer`).\n",
        "\n",
        "7. **Output Format**: Return the output as a JSON object with two keys:\n",
        "   - `\"markdown\"`: A single markdown string containing all the extracted content, formatted as described above.\n",
        "   - `\"chunks\"`: A list of objects, where each object represents a chunk of content. Each chunk should include:\n",
        "     - `\"text\"`: The extracted content as a string.\n",
        "     - `\"grounding\"`: The bounding box and page number information.\n",
        "     - `\"chunk_type\"`: The type of chunk (e.g., `text`, `table`, `figure`).\n",
        "     - `\"chunk_id\"`: A unique identifier for the chunk.\n",
        "\n",
        "**Example Output:**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"markdown\": \"## Heading 1\\n\\nThis is a paragraph of text.\\n\\n### Subheading\\n\\n- Bullet point 1\\n- Bullet point 2\\n\\n## Table 1\\n\\n| Column 1 | Column 2 |\\n|----------|----------|\\n| Data 1   | Data 2   |\\n\\n## Figure 1\\n\\nThis is a description of a bar chart showing...\\n\\n### Page Number\\n\\n1\\n\\n### Page Footer\\n\\n2024 Annual Report\",\n",
        "  \"chunks\": [\n",
        "    {\n",
        "      \"text\": \"## Heading 1\\n\\nThis is a paragraph of text.\",\n",
        "      \"grounding\": [\n",
        "        {\n",
        "          \"box\": {\n",
        "            \"l\": 0.1,\n",
        "            \"t\": 0.2,\n",
        "            \"r\": 0.9,\n",
        "            \"b\": 0.3\n",
        "          },\n",
        "          \"page\": 0\n",
        "        }\n",
        "      ],\n",
        "      \"chunk_type\": \"text\",\n",
        "      \"chunk_id\": \"12345\"\n",
        "    },\n",
        "    {\n",
        "      \"text\": \"## Table 1\\n\\n| Column 1 | Column 2 |\\n|----------|----------|\\n| Data 1   | Data 2   |\",\n",
        "      \"grounding\": [\n",
        "        {\n",
        "          \"box\": {\n",
        "            \"l\": 0.1,\n",
        "            \"t\": 0.4,\n",
        "            \"r\": 0.9,\n",
        "            \"b\": 0.5\n",
        "          },\n",
        "          \"page\": 0\n",
        "        }\n",
        "      ],\n",
        "      \"chunk_type\": \"table\",\n",
        "      \"chunk_id\": \"67890\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "**Instructions:**\n",
        "- Ensure the output is well-structured and easy to read.\n",
        "- Handle edge cases (e.g., missing data, overlapping elements) gracefully.\n",
        "- Use consistent formatting for markdown and JSON.\n",
        "\n",
        "      **TEXT STARTS HERE**:\n",
        "        \"\"\"\n",
        "        markdown = generate_markdown_from_page(text, prompt, gemini_api_key)\n",
        "        markdowns[page_num] = markdown\n",
        "    return markdowns\n",
        "\n",
        "\n",
        "# Step 3: Create the RAG System (Using FAISS)\n",
        "def get_embeddings_from_text(texts):\n",
        "    \"\"\"\n",
        "    Convert a list of texts (markdowns) to vector embeddings.\n",
        "    Placeholder function, replace it with actual embedding model.\n",
        "    \"\"\"\n",
        "    return np.random.rand(len(texts), 512)  # Dummy embeddings for illustration\n",
        "\n",
        "\n",
        "def create_faiss_index(markdowns):\n",
        "    \"\"\"\n",
        "    Create a FAISS index to store and retrieve markdown data.\n",
        "    \"\"\"\n",
        "    embeddings = get_embeddings_from_text(list(markdowns.values()))\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])  # Flat index for simplicity\n",
        "    index.add(embeddings)\n",
        "    return index, embeddings\n",
        "\n",
        "\n",
        "def retrieve_relevant_markdowns(query, index, embeddings, markdowns, k=1):\n",
        "    \"\"\"\n",
        "    Retrieve the most relevant markdown(s) for the user query from FAISS index.\n",
        "    \"\"\"\n",
        "    query_embedding = get_embeddings_from_text([query])[0]  # Get embedding for the query\n",
        "    _, indices = index.search(np.array([query_embedding]), k)  # Search for k nearest neighbors\n",
        "    relevant_markdowns = [markdowns[i] for i in indices[0]]\n",
        "    return relevant_markdowns\n",
        "\n",
        "\n",
        "# Step 4: Build the Chatbot\n",
        "def generate_response_from_markdowns(query, relevant_markdowns, api_key):\n",
        "    \"\"\"\n",
        "    Generate a response from the relevant markdowns by feeding them back to Gemini API.\n",
        "    \"\"\"\n",
        "    context = \" \".join(relevant_markdowns)\n",
        "    prompt = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
        "    return generate_markdown_from_page(prompt, prompt, api_key)\n",
        "\n",
        "\n",
        "def chatbot(query, index, embeddings, markdowns, api_key):\n",
        "    \"\"\"\n",
        "    Chatbot function that uses the RAG system to generate responses.\n",
        "    \"\"\"\n",
        "    relevant_markdowns = retrieve_relevant_markdowns(query, index, embeddings, markdowns)\n",
        "    response = generate_response_from_markdowns(query, relevant_markdowns, api_key)\n",
        "    return response\n",
        "\n",
        "\n",
        "# Full Pipeline to read PDF, generate markdown, create RAG system, and use the chatbot\n",
        "def main(pdf_path, gemini_api_key, user_query):\n",
        "    \"\"\"\n",
        "    Full pipeline: Read PDF -> Generate markdown -> Create RAG system -> Query chatbot\n",
        "    \"\"\"\n",
        "    # Step 1: Process the PDF to generate markdown for each page\n",
        "    markdowns = process_pdf(pdf_path, gemini_api_key)\n",
        "\n",
        "    # Step 2: Create the FAISS-based RAG system\n",
        "    index, embeddings = create_faiss_index(markdowns)\n",
        "\n",
        "    # Step 3: Query the chatbot and get a response\n",
        "    response = chatbot(user_query, index, embeddings, markdowns, gemini_api_key)\n",
        "    return response\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwll0yUhwyfo",
        "outputId": "20140e45-06f1-4494-e0a5-243ff819dbb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot Response: The table provides the average balance of credit cards in 2024 which is $17.3 billions and the average rate of 21.53%. It does not provide the revenues.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "pdf_path = 'sample.pdf'  # Path to your PDF\n",
        "gemini_api_key = 'AIzaSyA0hQWaUYTRVzD7EGKAtZAYnCYKpr3UEC4'  # Your Gemini API key\n",
        "user_query = \"What is the Card revenues for 2024?\"  # Example user query\n",
        "\n",
        "response = main(pdf_path, gemini_api_key, user_query)\n",
        "print(f\"Chatbot Response: {response}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
